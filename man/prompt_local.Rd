% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prompt.R
\name{prompt_local}
\alias{prompt_local}
\title{Prompt Local LLM}
\usage{
prompt_local(prompt, context, model, port = 1234, temperature = 0)
}
\arguments{
\item{prompt}{A string containing the prompt to give the LLM.}

\item{context}{A string containing the system context to give the LLM.}

\item{model}{A string containing the model name in LMStudio.}

\item{port}{A number or string containing the port number set in LMStudio
(default = 1234).}

\item{temperature}{A number representing how random vs. deterministic the
output is. Set to 0 to always get the same response.}
}
\value{
A string containing the LLM's response to your prompt.
}
\description{
Prompt local large language model from LMStudio
}
\examples{
prompt_local("Introduce yourself.", "Always answer in rhymes.", "lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF")
}
