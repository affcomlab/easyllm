% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/prompt.R
\name{prompt_local}
\alias{prompt_local}
\title{Prompt Local LLM}
\usage{
prompt_local(prompt, model, context = NULL, port = 1234, temperature = 0)
}
\arguments{
\item{prompt}{A required string containing the prompt to give the LLM.}

\item{model}{A required string containing the model name in LMStudio.}

\item{context}{Either NULL or a string containing the system context to give
the LLM (default = NULL).}

\item{port}{A number or string containing the port number set in LMStudio
(default = 1234).}

\item{temperature}{A number representing how random vs. deterministic the
output is. Set to 0 to always get the same response.}
}
\value{
A string containing the LLM's response to your prompt.
}
\description{
Prompt local large language model from LMStudio
}
\examples{
prompt_local(
  prompt = "Introduce yourself.",
  context = "Always answer in rhymes.",
  model = "lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF"
)
}
